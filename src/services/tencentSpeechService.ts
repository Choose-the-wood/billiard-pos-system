/**
 * è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«æœåŠ¡
 * æä¾›å®æ—¶è¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘æ–‡ä»¶è¯†åˆ«åŠŸèƒ½
 */

export interface RecognitionResult {
  text: string;
  confidence: number;
  isFinal: boolean;
  timestamp: number;
}

export interface SpeechEventListeners {
  onResult?: (result: RecognitionResult) => void;
  onError?: (error: string) => void;
  onStart?: () => void;
  onEnd?: () => void;
}

export class TencentSpeechService {
  private static instance: TencentSpeechService | null = null;
  private mediaRecorder: MediaRecorder | null = null;
  private mediaStream: MediaStream | null = null;
  private audioChunks: Blob[] = [];
  private isRecording: boolean = false;
  private eventListeners: SpeechEventListeners | null = null;

  // è…¾è®¯äº‘é…ç½®
  private config = {
    region: "ap-beijing",
    format: "wav",
    sampleRate: 16000,
    enablePunctuationPrediction: true,
    enableInverseTextNormalization: true,
    enableVoiceDetection: true,
  };

  private constructor() {
    // ç§æœ‰æ„é€ å‡½æ•°ï¼Œç¡®ä¿å•ä¾‹æ¨¡å¼
  }

  /**
   * è·å–å•ä¾‹å®ä¾‹
   */
  static getInstance(): TencentSpeechService {
    if (!TencentSpeechService.instance) {
      TencentSpeechService.instance = new TencentSpeechService();
    }
    return TencentSpeechService.instance;
  }

  /**
   * è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
   */
  setEventListeners(listeners: SpeechEventListeners): void {
    this.eventListeners = listeners;
  }

  /**
   * æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
   */
  isSupported(): boolean {
    return (
      typeof navigator !== "undefined" &&
      typeof navigator.mediaDevices !== "undefined" &&
      typeof navigator.mediaDevices.getUserMedia === "function" &&
      typeof MediaRecorder !== "undefined"
    );
  }

  /**
   * è·å–æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼ˆä¼˜å…ˆè…¾è®¯äº‘æ”¯æŒçš„æ ¼å¼ï¼‰
   */
  private getSupportedMimeType(): string {
    // ä¼˜å…ˆä½¿ç”¨è…¾è®¯äº‘ç›´æ¥æ”¯æŒçš„æ ¼å¼
    const types = [
      "audio/wav", // è…¾è®¯äº‘æ”¯æŒ
      "audio/mp4", // è…¾è®¯äº‘æ”¯æŒï¼ˆm4aï¼‰
      "audio/webm;codecs=opus", // éœ€è¦è½¬æ¢
      "audio/webm", // éœ€è¦è½¬æ¢
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        console.log(`ğŸµ é€‰æ‹©éŸ³é¢‘æ ¼å¼: ${type}`);
        return type;
      }
    }

    return "audio/wav"; // é»˜è®¤æ ¼å¼
  }

  /**
   * å¼€å§‹è¯­éŸ³è¯†åˆ«
   */
  async startRecognition(): Promise<void> {
    if (!this.isSupported()) {
      throw new Error("å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½");
    }

    if (this.isRecording) {
      throw new Error("è¯­éŸ³è¯†åˆ«å·²åœ¨è¿›è¡Œä¸­");
    }

    try {
      // è·å–éº¦å…‹é£æƒé™
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.config.sampleRate,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });

      // åˆ›å»ºMediaRecorderï¼Œä¼˜å…ˆä½¿ç”¨WAVæ ¼å¼
      let mimeType = "audio/wav";
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = this.getSupportedMimeType();
      }

      console.log("ğŸ¤ ä½¿ç”¨éŸ³é¢‘æ ¼å¼:", mimeType);

      this.mediaRecorder = new MediaRecorder(this.mediaStream, {
        mimeType: mimeType,
        audioBitsPerSecond: 128000, // è®¾ç½®éŸ³é¢‘æ¯”ç‰¹ç‡
      });

      // è®¾ç½®å½•éŸ³äº‹ä»¶
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
        }
      };

      this.mediaRecorder.onstop = () => {
        this.processAudioBlob();
        this.cleanup();
      };

      this.mediaRecorder.onerror = (event) => {
        this.eventListeners?.onError?.("å½•éŸ³è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯");
        this.cleanup();
      };

      // å¼€å§‹å½•éŸ³
      this.audioChunks = [];
      this.mediaRecorder.start(1000); // æ¯ç§’æ”¶é›†ä¸€æ¬¡æ•°æ®
      this.isRecording = true;

      this.eventListeners?.onStart?.();
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥";
      this.eventListeners?.onError?.(errorMessage);
      throw error;
    }
  }

  /**
   * åœæ­¢è¯­éŸ³è¯†åˆ«
   */
  stopRecognition(): void {
    if (this.mediaRecorder && this.mediaRecorder.state === "recording") {
      this.mediaRecorder.stop();
    }

    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach((track) => track.stop());
      this.mediaStream = null;
    }

    this.isRecording = false;
    this.eventListeners?.onEnd?.();
  }

  /**
   * è¯†åˆ«éŸ³é¢‘æ–‡ä»¶
   */
  async recognizeAudioFile(file: File): Promise<void> {
    try {
      this.eventListeners?.onStart?.();

      // å°†æ–‡ä»¶è½¬æ¢ä¸ºBase64
      const base64Audio = await this.convertBlobToBase64(file);

      // è°ƒç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«API
      await this.callTencentSpeechAPI(base64Audio, file.type);
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "éŸ³é¢‘æ–‡ä»¶è¯†åˆ«å¤±è´¥";
      this.eventListeners?.onError?.(errorMessage);
    } finally {
      this.eventListeners?.onEnd?.();
    }
  }

  /**
   * å¤„ç†å½•éŸ³æ•°æ®
   */
  private processAudioBlob(): void {
    if (this.audioChunks.length === 0) {
      return;
    }

    try {
      // åˆå¹¶éŸ³é¢‘æ•°æ®
      const audioBlob = new Blob(this.audioChunks, {
        type: this.getSupportedMimeType(),
      });

      console.log("ğŸµ å¤„ç†éŸ³é¢‘Blob:", {
        size: audioBlob.size,
        type: audioBlob.type,
      });

      // æ£€æŸ¥éŸ³é¢‘æ•°æ®å¤§å°
      if (audioBlob.size < 1000) {
        console.warn("âš ï¸ è­¦å‘Šï¼šéŸ³é¢‘æ•°æ®å¯èƒ½å¤ªçŸ­ï¼Œå¤§å°:", audioBlob.size);
      }

      // è°ƒç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«API
      this.callTencentSpeechAPIFromBlob(audioBlob);
    } catch (error) {
      this.eventListeners?.onError?.("å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥");
    }
  }

  /**
   * ä»Blobè°ƒç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«API
   */
  private async callTencentSpeechAPIFromBlob(audioBlob: Blob): Promise<void> {
    try {
      let processedBlob = audioBlob;

      // å¦‚æœæ˜¯WebMæ ¼å¼ï¼Œè½¬æ¢ä¸ºWAV
      if (audioBlob.type.includes("webm")) {
        console.log("ğŸ”„ æ£€æµ‹åˆ°WebMæ ¼å¼ï¼Œå¼€å§‹è½¬æ¢ä¸ºWAV...");
        try {
          processedBlob = await this.convertWebMToWAV(audioBlob);
          console.log("âœ… WebMè½¬WAVæˆåŠŸï¼Œæ–°æ ¼å¼:", processedBlob.type);
        } catch (conversionError) {
          console.warn("âš ï¸ WebMè½¬WAVå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ ¼å¼:", conversionError);
          // è½¬æ¢å¤±è´¥æ—¶ä»ç„¶å°è¯•ä½¿ç”¨åŸå§‹æ ¼å¼
          processedBlob = audioBlob;
        }
      }

      const base64Audio = await this.convertBlobToBase64(processedBlob);
      console.log("ğŸ“Š Base64éŸ³é¢‘æ•°æ®é•¿åº¦:", base64Audio.length);

      await this.callTencentSpeechAPI(base64Audio, processedBlob.type);
    } catch (error) {
      console.error("âŒ ä»Blobè°ƒç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«APIå¤±è´¥:", error);
      this.eventListeners?.onError?.(
        `è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`
      );
    }
  }

  /**
   * å°†WebMéŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼
   */
  private async convertWebMToWAV(webmBlob: Blob): Promise<Blob> {
    return new Promise((resolve, reject) => {
      try {
        const audioContext = new (window.AudioContext ||
          (window as any).webkitAudioContext)();
        const fileReader = new FileReader();

        fileReader.onload = async (e) => {
          try {
            const arrayBuffer = e.target?.result as ArrayBuffer;
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

            // è½¬æ¢ä¸ºWAVæ ¼å¼
            const wavBlob = this.audioBufferToWAV(audioBuffer);
            resolve(wavBlob);
          } catch (error) {
            console.error("éŸ³é¢‘è§£ç å¤±è´¥:", error);
            reject(error);
          }
        };

        fileReader.onerror = reject;
        fileReader.readAsArrayBuffer(webmBlob);
      } catch (error) {
        console.error("éŸ³é¢‘è½¬æ¢å¤±è´¥:", error);
        reject(error);
      }
    });
  }

  /**
   * å°†AudioBufferè½¬æ¢ä¸ºWAVæ ¼å¼çš„Blob
   */
  private audioBufferToWAV(audioBuffer: AudioBuffer): Blob {
    const numberOfChannels = 1; // å•å£°é“
    const sampleRate = this.config.sampleRate;
    const format = 1; // PCM
    const bitDepth = 16;

    const length = audioBuffer.length;
    const arrayBuffer = new ArrayBuffer(44 + length * 2);
    const view = new DataView(arrayBuffer);

    // WAVæ–‡ä»¶å¤´
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };

    // RIFFæ ‡è¯†ç¬¦
    writeString(0, "RIFF");
    // æ–‡ä»¶é•¿åº¦
    view.setUint32(4, 36 + length * 2, true);
    // WAVEæ ‡è¯†ç¬¦
    writeString(8, "WAVE");
    // fmtå­å—
    writeString(12, "fmt ");
    // fmtå­å—é•¿åº¦
    view.setUint32(16, 16, true);
    // éŸ³é¢‘æ ¼å¼
    view.setUint16(20, format, true);
    // å£°é“æ•°
    view.setUint16(22, numberOfChannels, true);
    // é‡‡æ ·ç‡
    view.setUint32(24, sampleRate, true);
    // å­—èŠ‚ç‡
    view.setUint32(28, (sampleRate * numberOfChannels * bitDepth) / 8, true);
    // å—å¯¹é½
    view.setUint16(32, (numberOfChannels * bitDepth) / 8, true);
    // ä½æ·±åº¦
    view.setUint16(34, bitDepth, true);
    // dataå­å—
    writeString(36, "data");
    // dataå­å—é•¿åº¦
    view.setUint32(40, length * 2, true);

    // å†™å…¥éŸ³é¢‘æ•°æ®
    const channelData = audioBuffer.getChannelData(0);
    let offset = 44;
    for (let i = 0; i < length; i++) {
      const sample = Math.max(-1, Math.min(1, channelData[i]));
      view.setInt16(offset, sample * 0x7fff, true);
      offset += 2;
    }

    return new Blob([arrayBuffer], { type: "audio/wav" });
  }

  /**
   * è°ƒç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«API
   */
  private async callTencentSpeechAPI(
    base64Audio: string,
    audioType: string
  ): Promise<void> {
    try {
      // è…¾è®¯äº‘æ”¯æŒçš„æ ¼å¼æ˜ å°„
      let format = "wav"; // é»˜è®¤æ ¼å¼
      let needsConversion = false;

      if (audioType.includes("webm")) {
        // WebMæ ¼å¼éœ€è¦è½¬æ¢ä¸ºWAV
        format = "wav";
        needsConversion = true;
        console.log("ğŸ”„ æ£€æµ‹åˆ°WebMæ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºWAV");
      } else if (audioType.includes("mp4") || audioType.includes("m4a")) {
        format = "m4a";
      } else if (audioType.includes("mp3")) {
        format = "mp3";
      } else if (audioType.includes("wav")) {
        format = "wav";
      } else if (audioType.includes("pcm")) {
        format = "pcm";
      }

      console.log(`ğŸ”„ éŸ³é¢‘æ ¼å¼å¤„ç†: ${audioType} -> ${format}`);

      // å‡†å¤‡è¯·æ±‚æ•°æ®
      const requestData = {
        audioData: base64Audio,
        format: format,
        sample_rate: this.config.sampleRate,
      };

      console.log("ğŸ“¤ å‘é€è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«è¯·æ±‚:", {
        ...requestData,
        audioData: `[Base64éŸ³é¢‘æ•°æ®ï¼Œé•¿åº¦: ${base64Audio.length}]`,
      });

      // é€šè¿‡ä»£ç†æœåŠ¡å™¨è°ƒç”¨è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«API
      const response = await fetch(
        "http://localhost:3001/api/speech/recognize",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(requestData),
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(
          `è…¾è®¯äº‘APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText} - ${errorText}`
        );
      }

      const result = await response.json();
      console.log("ğŸ“¥ è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«APIå“åº”:", result);

      if (result.success && result.result) {
        // è¯†åˆ«æˆåŠŸ
        const recognitionResult: RecognitionResult = {
          text: result.result,
          confidence: 0.9, // è…¾è®¯äº‘é»˜è®¤ç½®ä¿¡åº¦
          isFinal: true,
          timestamp: Date.now(),
        };

        console.log("âœ… è¯­éŸ³è¯†åˆ«æˆåŠŸ:", recognitionResult);
        this.eventListeners?.onResult?.(recognitionResult);
      } else {
        // å¦‚æœè¯†åˆ«ç»“æœä¸ºç©ºï¼Œå¯èƒ½æ˜¯éŸ³é¢‘è´¨é‡é—®é¢˜
        if (!result.result || result.result.trim() === "") {
          console.warn("âš ï¸ è¯­éŸ³è¯†åˆ«ç»“æœä¸ºç©ºï¼Œå¯èƒ½åŸå› ï¼š");
          console.warn("   1. éŸ³é¢‘ä¸­æ²¡æœ‰æ¸…æ™°çš„è¯­éŸ³å†…å®¹");
          console.warn("   2. éŸ³é¢‘è´¨é‡ä¸ä½³æˆ–å™ªéŸ³è¿‡å¤§");
          console.warn("   3. éŸ³é¢‘æ—¶é•¿è¿‡çŸ­");
          this.eventListeners?.onError?.(
            "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œè¯·ç¡®ä¿è¯´è¯æ¸…æ™°å¹¶é‡è¯•"
          );
        } else {
          throw new Error(result.message || result.error || "è¯­éŸ³è¯†åˆ«å¤±è´¥");
        }
      }
    } catch (error) {
      console.error("âŒ è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«APIè°ƒç”¨å¤±è´¥:", error);
      this.eventListeners?.onError?.(
        `è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error instanceof Error ? error.message : "æœªçŸ¥é”™è¯¯"}`
      );
    }
  }

  /**
   * å°†Blobè½¬æ¢ä¸ºBase64
   */
  private async convertBlobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        // ç§»é™¤data:audio/xxx;base64,å‰ç¼€
        const base64 = result.split(",")[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  /**
   * æ¸…ç†èµ„æº
   */
  private cleanup(): void {
    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach((track) => track.stop());
      this.mediaStream = null;
    }

    this.mediaRecorder = null;
    this.audioChunks = [];
    this.isRecording = false;
  }

  /**
   * è·å–å½“å‰å½•éŸ³çŠ¶æ€
   */
  getRecordingState(): boolean {
    return this.isRecording;
  }

  /**
   * è·å–é…ç½®ä¿¡æ¯
   */
  getConfig() {
    return { ...this.config };
  }

  /**
   * æ›´æ–°é…ç½®
   */
  updateConfig(newConfig: Partial<typeof this.config>): void {
    this.config = { ...this.config, ...newConfig };
  }
}

export default TencentSpeechService;
